{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment-8.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# CS354N\n",
        "---\n",
        "**Name: Somya Mehta**\n",
        "\n",
        "**Roll No.: 190001058**\n",
        "\n",
        "**Assignment - 8**\n",
        "\n"
      ],
      "metadata": {
        "id": "cZhc_4kMspA7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kAXIDQO41olI",
        "outputId": "27bb9516-957b-4502-b195-0245ccd641b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy = \n",
            "79.55801104972376\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "import csv\n",
        "import math\n",
        "\n",
        "\n",
        "def activation_function(val):\n",
        "    # for extreme values since sigmoid function 1/(1+e^-val)\n",
        "    if val <= -100:\n",
        "        return 0\n",
        "    if val >= 100:\n",
        "        return 1\n",
        "    return 1 / (1 + math.exp(-val))\n",
        "\n",
        "def derivative_Of_activation_function(x):\n",
        "    # derivative of sigmoid\n",
        "    return activation_function(x) * (1 - activation_function(x))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class SingleHiddenLayerNN:\n",
        "#N is number of input features, M denotes neurons in hidden layer\n",
        "    def __init__(self, N, M):\n",
        "        self.N = N\n",
        "        self.M = M\n",
        "        self.hidden_weights = []\n",
        "        self.hidden_baises = []\n",
        "        for _ in range(M):\n",
        "            self.hidden_baises.append(random.uniform(-0.1, 0.1))\n",
        "            wgt = []\n",
        "            for i in range(N):\n",
        "                wgt.append(random.uniform(-0.1, 0.1))\n",
        "            self.hidden_weights.append(wgt)\n",
        "\n",
        "        self.output_bais = random.uniform(-0.1, 0.1)\n",
        "        wgt = []\n",
        "        for i in range(M):\n",
        "            wgt.append(random.uniform(-0.1, 0.1))\n",
        "        self.output_weights = wgt\n",
        "\n",
        "    def test(self, testData, testLabels):\n",
        "        correct = 0\n",
        "        wrong = 0\n",
        "        for ii in range(len(testData)):\n",
        "            Data = testData[ii]\n",
        "            Label = testLabels[ii]\n",
        "\n",
        "            sum_hidden_layer = []\n",
        "            activated_sum_hidden_layer = []\n",
        "            for i in range(self.M):\n",
        "                val = self.hidden_baises[i]\n",
        "                for j in range(self.N):\n",
        "                    val += self.hidden_weights[i][j] * Data[j]\n",
        "                sum_hidden_layer.append(val)\n",
        "                activated_sum_hidden_layer.append(activation_function(val))\n",
        "\n",
        "            sum_output_layer = self.output_bais\n",
        "            activated_sum_output_layer = 0\n",
        "            for i in range(self.M):\n",
        "                sum_output_layer += activated_sum_hidden_layer[i] * self.output_weights[i]\n",
        "            activated_sum_output_layer = activation_function(sum_output_layer)\n",
        "\n",
        "            if activated_sum_output_layer > 0.5:\n",
        "                if Label == 1:\n",
        "                    correct += 1\n",
        "                else:\n",
        "                    wrong += 1\n",
        "            else:\n",
        "                if Label == 0:\n",
        "                    correct += 1\n",
        "                else:\n",
        "                    wrong += 1\n",
        "        print(\"accuracy = \")\n",
        "        print(float(correct) / float(correct + wrong)*100)\n",
        "\n",
        "    def train(self, trainData, trainLabels, learning_rate, iterations):\n",
        "        for _ in range(iterations):\n",
        "            for ii in range(len(trainData)):\n",
        "                Data = trainData[ii]\n",
        "                Label = trainLabels[ii]\n",
        "\n",
        "                sum_hidden_layer = []\n",
        "                activated_sum_hidden_layer = []\n",
        "                for i in range(self.M):\n",
        "                    val = self.hidden_baises[i]\n",
        "                    for j in range(self.N):\n",
        "                        val += self.hidden_weights[i][j] * Data[j]\n",
        "                    sum_hidden_layer.append(val)\n",
        "                    activated_sum_hidden_layer.append(activation_function(val))\n",
        "\n",
        "                sum_output_layer = self.output_bais\n",
        "                activated_sum_output_layer = 0\n",
        "                for i in range(self.M):\n",
        "                    sum_output_layer += activated_sum_hidden_layer[i] * self.output_weights[i]\n",
        "                activated_sum_output_layer = activation_function(sum_output_layer)\n",
        "\n",
        "                if activated_sum_output_layer > 0.5:\n",
        "                    activated_sum_output_layer = 1\n",
        "                else:\n",
        "                    activated_sum_output_layer = 0\n",
        "\n",
        "                #update output layer weights\n",
        "                for i in range(self.M):\n",
        "                    self.output_weights[i] += -1 * learning_rate * (activated_sum_output_layer -Label) * derivative_Of_activation_function(sum_output_layer) * activated_sum_hidden_layer[i]\n",
        "\n",
        "                #update output layer baises\n",
        "                self.output_bais += -1 * learning_rate * (activated_sum_output_layer - Label) * derivative_Of_activation_function(sum_output_layer)\n",
        "\n",
        "                #update hidden layer weights\n",
        "                for i in range(self.M):\n",
        "                    for j in range(self.N):\n",
        "                        self.hidden_weights[i][j] += -1 * learning_rate * (activated_sum_output_layer - Label) * derivative_Of_activation_function(sum_output_layer) * self.output_weights[i] * derivative_Of_activation_function(sum_hidden_layer[i]) * Data[j]\n",
        "\n",
        "                #update hidden layer baises\n",
        "                for i in range(self.M):\n",
        "                    self.hidden_baises[i] += -1 * learning_rate * (activated_sum_output_layer -Label) * derivative_Of_activation_function(sum_output_layer) * self.output_weights[i] * derivative_Of_activation_function(sum_hidden_layer[i])\n",
        "\n",
        "\n",
        "\n",
        "# read csv file\n",
        "def Read_file(file):\n",
        "    fileptr = open(file)\n",
        "    csvreader = csv.reader(fileptr)\n",
        "    header = next(csvreader)\n",
        "    rows = []\n",
        "    for row in csvreader:\n",
        "        rows.append(row)\n",
        "    fileptr.close()\n",
        "    return rows\n",
        "\n",
        "\n",
        "testDataFiles = Read_file('testData.csv')\n",
        "testLabelsFiles = Read_file('testLabels.csv')\n",
        "trainDataFiles = Read_file('trainData.csv')\n",
        "trainLabelsFiles = Read_file('trainLabels.csv')\n",
        "\n",
        "testData = []\n",
        "for row in testDataFiles:\n",
        "    a = []\n",
        "    for x in row:\n",
        "        a.append(float(x))\n",
        "    testData.append(a)\n",
        "\n",
        "trainData = []\n",
        "for row in trainDataFiles:\n",
        "    a = []\n",
        "    for x in row:\n",
        "        a.append(float(x))\n",
        "    trainData.append(a)\n",
        "\n",
        "testLabels = []\n",
        "for row in testLabelsFiles:\n",
        "    testLabels.append(int(row[0]) - int(5))\n",
        "\n",
        "trainLabels = []\n",
        "for row in trainLabelsFiles:\n",
        "    trainLabels.append(float(row[0]) - 5.0)\n",
        "# for noNodes in range(5,15):\n",
        "# checking for 5 hidden nodes\n",
        "neuralNet = SingleHiddenLayerNN(len(trainData[0]),5)\n",
        "\n",
        "neuralNet.train(trainData, trainLabels, 0.001, 1000)\n",
        "\n",
        "neuralNet.test(testData, testLabels)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!jupyter nbconvert --to html assignment10.ipynb  "
      ],
      "metadata": {
        "id": "xuRc89AQSiKn",
        "outputId": "0d71aae8-4771-4546-b056-db201b6cebdf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NbConvertApp] Converting notebook assignment10.ipynb to html\n",
            "[NbConvertApp] Writing 357177 bytes to assignment10.html\n"
          ]
        }
      ]
    }
  ]
}